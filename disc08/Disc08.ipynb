{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"this was a good movie\"\n",
    "s2 = \"this was boring\"\n",
    "s3 = \"a good action movie\"\n",
    "s4 = \"I like this movie\"\n",
    "s5 = \"boring movie and bad acting\"\n",
    "s6 = \"bad boring movie\"\n",
    "s7 = \"good acting\"\n",
    "s8 = \"the worst movie I have ever seen\"\n",
    "sentences = [s1,s2,s3,s4,s5,s6,s7,s8]\n",
    "\n",
    "# 0 means bad and 1 means good\n",
    "l1 = 1\n",
    "l2 = 0\n",
    "l3 = 1\n",
    "l4 = 1\n",
    "l5 = 0\n",
    "labels = [l1,l2,l3,l4,l5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCountVec(S):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(S).toarray()\n",
    "    df = pd.DataFrame(X, columns = vectorizer.get_feature_names())\n",
    "    print(df.head(25))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTfidfVec(S):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(S).toarray()\n",
    "\n",
    "    df = pd.DataFrame(X, columns = vectorizer.get_feature_names())\n",
    "    print(df.head(25))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   acting  action  and  bad  boring  ever  good  have  like  movie  seen  the  \\\n",
      "0       0       0    0    0       0     0     1     0     0      1     0    0   \n",
      "1       0       0    0    0       1     0     0     0     0      0     0    0   \n",
      "2       0       1    0    0       0     0     1     0     0      1     0    0   \n",
      "3       0       0    0    0       0     0     0     0     1      1     0    0   \n",
      "4       1       0    1    1       1     0     0     0     0      1     0    0   \n",
      "5       0       0    0    1       1     0     0     0     0      1     0    0   \n",
      "6       1       0    0    0       0     0     1     0     0      0     0    0   \n",
      "7       0       0    0    0       0     1     0     1     0      1     1    1   \n",
      "\n",
      "   this  was  worst  \n",
      "0     1    1      0  \n",
      "1     1    1      0  \n",
      "2     0    0      0  \n",
      "3     1    0      0  \n",
      "4     0    0      0  \n",
      "5     0    0      0  \n",
      "6     0    0      0  \n",
      "7     0    0      1  \n"
     ]
    }
   ],
   "source": [
    "Count = getCountVec(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     acting   action       and       bad    boring      ever      good  \\\n",
      "0  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  0.511617   \n",
      "1  0.000000  0.00000  0.000000  0.000000  0.546934  0.000000  0.000000   \n",
      "2  0.000000  0.75107  0.000000  0.000000  0.000000  0.000000  0.543168   \n",
      "3  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "4  0.470158  0.00000  0.560996  0.470158  0.405708  0.000000  0.000000   \n",
      "5  0.000000  0.00000  0.000000  0.690041  0.595449  0.000000  0.000000   \n",
      "6  0.757092  0.00000  0.000000  0.000000  0.000000  0.000000  0.653308   \n",
      "7  0.000000  0.00000  0.000000  0.000000  0.000000  0.436448  0.000000   \n",
      "\n",
      "       have     like     movie      seen       the      this       was  \\\n",
      "0  0.000000  0.00000  0.353517  0.000000  0.000000  0.511617  0.592892   \n",
      "1  0.000000  0.00000  0.000000  0.000000  0.000000  0.546934  0.633819   \n",
      "2  0.000000  0.00000  0.375318  0.000000  0.000000  0.000000  0.000000   \n",
      "3  0.000000  0.75107  0.375318  0.000000  0.000000  0.543168  0.000000   \n",
      "4  0.000000  0.00000  0.280336  0.000000  0.000000  0.000000  0.000000   \n",
      "5  0.000000  0.00000  0.411442  0.000000  0.000000  0.000000  0.000000   \n",
      "6  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "7  0.436448  0.00000  0.218098  0.436448  0.436448  0.000000  0.000000   \n",
      "\n",
      "      worst  \n",
      "0  0.000000  \n",
      "1  0.000000  \n",
      "2  0.000000  \n",
      "3  0.000000  \n",
      "4  0.000000  \n",
      "5  0.000000  \n",
      "6  0.000000  \n",
      "7  0.436448  \n"
     ]
    }
   ],
   "source": [
    "TFIDF = getTfidfVec(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training & predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['bad boring movie', 0], ['good acting', 1], ['the worst movie I have ever seen', 1]]\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = SVC(probability=True)\n",
    "\n",
    "# train/fit the model\n",
    "model.fit(Count[:train_size],labels[:train_size])\n",
    "\n",
    "# predict\n",
    "pred = model.predict(Count[train_size:])\n",
    "\n",
    "# print\n",
    "print([[s,p] for s,p in zip(sentences[train_size:], pred)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tips for A6\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d) Convert Text data into vector \n",
    "\n",
    "We will now create a `CountVectorizer` object to transform the text data into vectors with numerical values. \n",
    "\n",
    "To do so, we will initialize a `CountVectorizer` object, and name it as `vectorizer`.\n",
    "\n",
    "We need to pass 4 arguments to initialize a CountVectorizer:\n",
    "  1. `analyzer`: `'word'` \n",
    "          Specify to analyze data from word-level.\n",
    "  2. `max_features`: `2000`\n",
    "          Set a max number of unique words.\n",
    "  3. `tokenizer`: `word_tokenize`\n",
    "          Set to tokenize the text data by using the word_tokenizer from NLTK .\n",
    "  4. `stop_words`: `stopwords.words('english')`\n",
    "          Set to remove all stopwords in English. We do this since they generally don't provide useful discriminative information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip**: Make a single call to CountVectorizer(dont call fit or fit transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1g) Defining the train & test sets\n",
    "\n",
    "We first set 80% of the data as the training set to train an SVM classifier. We will then test the learnt classifier on the remaining 20% of data samples (test set). (Reminder: For this homework assignment, we've already shuffled the data)\n",
    "\n",
    "- Calculate the number of training data samples (80% of total) and store it in `num_training`\n",
    "- Calculate the number of test data samples (20% of total) and store it in `num_testing`\n",
    "- Make sure both of these variables are of type `int`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip**: Make sure num_training and num_testing are integers!! and also make sure they sum up to the total data size.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "a = [1]*10\n",
    "train_size = int(len(a)*0.95)\n",
    "test_size = int(len(a)*0.05)\n",
    "\n",
    "print(train_size, test_size)\n",
    "print(len(a)==train_size + test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
